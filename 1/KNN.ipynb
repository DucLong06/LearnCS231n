{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import platform\n",
    "from six.moves import cPickle as pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NearestNeighbor(object):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def train(self, X, y):\n",
    "        self.Xtr = X\n",
    "        self.ytr = y\n",
    "\n",
    "    def distanceMatrix(self, X):\n",
    "        num_test = X.shape[0] \n",
    "        dis = np.zeros((num_test, (self.Xtr.shape[0])))  \n",
    "        \n",
    "        for i in range(num_test):\n",
    "            dis[i]= np.sqrt(np.sum(np.square(self.Xtr - X[i,:]), axis = 1)) \n",
    "        \n",
    "        return dis\n",
    "\n",
    "    def predict_labels(self, dists, k=1):\n",
    "        closest_y = []\n",
    "        num_test = dists.shape[0]\n",
    "        y_pred = np.zeros(num_test)\n",
    "        for i in range(num_test):\n",
    "            closest_y = np.argsort(dists[i])[:k]                 \n",
    "        \n",
    "            y_pred[i] = np.bincount(self.ytr[closest_y]).argmax()\n",
    "        return y_pred\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_CIFAR10(ROOT):\n",
    "    \"\"\" load all of cifar \"\"\"\n",
    "    xs = []\n",
    "    ys = []\n",
    "    for b in range(1,6):\n",
    "        f = os.path.join(ROOT, 'data_batch_%d' % (b, ))\n",
    "        X, Y = load_CIFAR_batch(f)\n",
    "        xs.append(X)\n",
    "        ys.append(Y)\n",
    "    Xtr = np.concatenate(xs)\n",
    "    Ytr = np.concatenate(ys)\n",
    "    del X, Y\n",
    "    Xte, Yte = load_CIFAR_batch(os.path.join(ROOT, 'test_batch'))\n",
    "    return Xtr, Ytr, Xte, Yte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_CIFAR_batch(filename):\n",
    "    \"\"\" load single batch of cifar \"\"\"\n",
    "    with open(filename, 'rb') as f:\n",
    "        datadict = load_pickle(f)\n",
    "        X = datadict['data']\n",
    "        Y = datadict['labels']\n",
    "        X = X.reshape(10000, 3, 32, 32).transpose(0,2,3,1).astype(\"float\")\n",
    "        Y = np.array(Y)\n",
    "        return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pickle(f):\n",
    "    version = platform.python_version_tuple()\n",
    "    if version[0] == '2':\n",
    "        return  pickle.load(f)\n",
    "    elif version[0] == '3':\n",
    "        return  pickle.load(f, encoding='latin1')\n",
    "    raise ValueError(\"invalid python version: {}\".format(version))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtr, Ytr, Xte, Yte = load_CIFAR10('assignment1_colab\\\\assignment1\\\\data\\\\cifar-10-python\\\\cifar-10-batches-py') # a magic function we provide\n",
    "# flatten out all images to be one-dimensional\n",
    "Xtr_rows = Xtr.reshape(Xtr.shape[0], 32 * 32 * 3) # Xtr_rows becomes 50000 x 3072\n",
    "Xte_rows = Xte.reshape(Xte.shape[0], 32 * 32 * 3) # Xte_rows becomes 10000 x 3072\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.352000\n",
      "accuracy: 0.339000\n",
      "accuracy: 0.354000\n",
      "accuracy: 0.353000\n",
      "accuracy: 0.334000\n",
      "accuracy: 0.312000\n",
      "accuracy: 0.302000\n"
     ]
    }
   ],
   "source": [
    "# assume we have Xtr_rows, Ytr, Xte_rows, Yte as before\n",
    "# recall Xtr_rows is 50,000 x 3072 matrix\n",
    "Xval_rows = Xtr_rows[:1000, :] # take first 1000 for validation\n",
    "Yval = Ytr[:1000]\n",
    "Xtr_rows = Xtr_rows[1000:, :] # keep last 49,000 for train\n",
    "Ytr = Ytr[1000:]\n",
    "\n",
    "# find hyperparameters that work best on the validation set\n",
    "validation_accuracies = []\n",
    "\n",
    "nn = NearestNeighbor()\n",
    "nn.train(Xtr_rows, Ytr)\n",
    "\n",
    "distance = nn.distanceMatrix(Xval_rows)\n",
    "\n",
    "# Yval_predict = nn.predict_labels(distance, k = 10)\n",
    "\n",
    "for k in [1, 3, 5, 10, 20, 50, 100]:\n",
    "# use a particular value of k and evaluation on validation dat\n",
    "# here we assume a modified NearestNeighbor class that can take a k as input\n",
    "    Yval_predict = nn.predict_labels(distance, k = k)\n",
    "    acc = np.mean(Yval_predict == Yval)\n",
    "    print ('accuracy: %f' % (acc,))\n",
    "# keep track of what works on the validation set\n",
    "    validation_accuracies.append((k, acc))\n",
    "  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
